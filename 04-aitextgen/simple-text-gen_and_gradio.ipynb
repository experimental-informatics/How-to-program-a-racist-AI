{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427a4c7d-af0b-4e96-889a-17fb67cb0474",
   "metadata": {},
   "source": [
    "# Generating Text from a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c5ad51-86c9-4f66-8c32-7a2b26456f80",
   "metadata": {},
   "source": [
    "### 0. check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98ff678-2eb2-4e75-83e0-f04e01bbb099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: Zeile 1: nvidia-smi: Kommando nicht gefunden.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05441ce6-2d4d-4d53-8b66-8561885a3d74",
   "metadata": {},
   "source": [
    "### 1. import aitextgen package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8ff66e-e024-4659-97b1-dabd95170941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b44bb74-d760-4b49-8f18-a3a4062b4046",
   "metadata": {},
   "source": [
    "### 2. load GPT-1?1 Model\n",
    "see docs: https://docs.aitextgen.io/load-model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bccd41-8043-48bf-aaad-61d6b331f045",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29adad21-99f0-41ae-b64f-7d9d99feea1e",
   "metadata": {},
   "source": [
    "#### 2.1 Eleuther's GPT-NEO\n",
    "\n",
    "see more info on: https://www.eleuther.ai/\n",
    "\n",
    "also, check out the demo of Neo's big sister »GPT-J-6B«: https://6b.eleuther.ai/ and »GPT-NeoX-20B« https://blog.eleuther.ai/announcing-20b/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b938ed-cddf-4c12-84c2-2f0ec325bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ai = aitextgen(model=\"EleutherAI/gpt-neo-125M\",to_gpu=True)\n",
    "#ai = aitextgen(model=\"EleutherAI/gpt-neo-350M\",to_gpu=True)\n",
    "#ai = aitextgen(model=\"EleutherAI/gpt-neo-1.3B\", to_fp16=True)\n",
    "#ai = aitextgen(model=\"EleutherAI/gpt-neo-2.7B\", to_fp16=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6995bf-ae03-4863-b437-d1fed09d43ad",
   "metadata": {},
   "source": [
    "#### 2.2 OpenAI's GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a062c08-9beb-4235-8d54-509ce4179d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without parameter, the default 124M GPT-2 model via Huggingface is loaded\n",
    "##ai = aitextgen()\n",
    "##ai = aitextgen(tf_gpt2=\"355M\", to_gpu=True)\n",
    "##ai = aitextgen(tf_gpt2=\"774M\", to_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e39846-c246-42d2-9d12-76ecb221522d",
   "metadata": {},
   "source": [
    "#### 2.3 OpenAI's GPT-2 running on a CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71077662-0f21-4d6e-8df6-bcae89230819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from aitextgen.utils import GPT2ConfigCPU\n",
    "config = GPT2ConfigCPU()\n",
    "ai = aitextgen(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd36348-7355-4160-936f-4356bfff93e1",
   "metadata": {},
   "source": [
    "#### 2.4 load finetuned model from huggingface\n",
    "choose one from: https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads&search=gpt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24ce763-cc0d-4492-8b2f-a0f4ca0a4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.ex.from: https://huggingface.co/huggingtweets/gecshater\n",
    "## ai = aitextgen(model=\"huggingtweets/gecshater\", ti_gpu=True)\n",
    "\n",
    "# or from: https://huggingface.co/minimaxir/hacker-news\n",
    "## ai = aitextgen(model=\"minimaxir/hacker-news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7737527-dcc0-4d63-b7cc-1f23ca390a96",
   "metadata": {},
   "source": [
    "### 3. create Function for text-generation\n",
    "\n",
    "some parameters for `ai.generate()` and friends:\n",
    "\n",
    "* **`n`**: Number of texts generated\n",
    "* **`prompt`**: Prompt that starts the generated text and is included in the generated text\n",
    "*  **`max_length`**: Number of tokens to generate (default: 200; for GPT-2, the maximum is 1024; for GPT Neo, the maximum is 2048)\n",
    "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
    "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
    "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
    "\n",
    "...for more parameters, see: https://docs.aitextgen.io/generate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e890df10-f851-40e5-aa91-371bb447c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai_text(inp):\n",
    "  generated_text = ai.generate_one(max_length = 100, \n",
    "                                   prompt = inp, \n",
    "                                   no_repeat_ngram_size = 3) #repetition_penalty = 1.9)\n",
    "  #print(type(generated_text))\n",
    "  return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd28dcf3-293e-4433-a1f8-8216e58e4437",
   "metadata": {},
   "source": [
    "### 4. generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb2d441-bc3a-42c9-a5cc-30627f993deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ai_text(\"A woman with a headscarf walks into\")\n",
    "#ai_text(\"Gehen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdfb2f6-09e6-4133-9b28-3f8c37f35809",
   "metadata": {},
   "source": [
    "# Create simple User Interface with gradio for Prompting \n",
    "get startet page: https://gradio.app/getting_started/\n",
    "\n",
    "documentation: https://gradio.app/docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b31107b-2a62-4127-a38c-54dab91493e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gradio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-43eca54f7d45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gradio'"
     ]
    }
   ],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25191e9e-e65e-4699-96bf-45b495ee1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = gr.outputs.Textbox()\n",
    "gr.Interface(ai_text,\"textbox\", output_text, title=\"simple graphic interface\",\n",
    "             description=\"AI Generated Content with GPT-Neo - via {aitextgen}\").launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
