{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Romeo & Julia with aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install aitextgen\n",
    "from aitextgen.TokenDataset import TokenDataset\n",
    "from aitextgen.tokenizers import train_tokenizer\n",
    "from aitextgen.utils import GPT2ConfigCPU\n",
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the downloaded Shakespeare text for training\n",
    "# file location: https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "file_name = \"input.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a custom BPE Tokenizer on the downloaded text\n",
    "# This will save one file: `aitextgen.tokenizer.json`, which contains the\n",
    "# information needed to rebuild the tokenizer.\n",
    "train_tokenizer(file_name)\n",
    "tokenizer_file = \"aitextgen.tokenizer.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2ConfigCPU is a mini variant of GPT-2 optimized for CPU-training\n",
    "# e.g. the # of input tokens here is 64 vs. 1024 for base GPT-2.\n",
    "config = GPT2ConfigCPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate aitextgen using the created tokenizer and config\n",
    "ai = aitextgen(tokenizer_file=tokenizer_file, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd8956884644e6a839cd872d76f1326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=40000.0), HTML(value='')), layout=Layout(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# You can build datasets for training by creating TokenDatasets,\n",
    "# which automatically processes the dataset with the appropriate size.\n",
    "data = TokenDataset(file_name, tokenizer_file=tokenizer_file, block_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whoami/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
      "  rank_zero_deprecation(\n",
      "/home/whoami/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:90: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "/home/whoami/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:167: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/whoami/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb896ac82acf431586c9540bf6971364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=50000.0), HTML(value='')), layout=Layout(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whoami/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1823: LightningDeprecationWarning: `trainer.progress_bar_dict` is deprecated in v1.5 and will be removed in v1.7. Use `ProgressBarBase.get_metrics` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ":\n",
      "I will be detern!\n",
      "\n",
      "TRANIO:\n",
      "My lord, letter, lord.\n",
      "\n",
      "\n",
      "LEONTES:\n",
      "Take not a choose and a sun,\n",
      "Is roose: it would not be done, my\n",
      "yount\n",
      "==========\n",
      "\u001b[1m10,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m10,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " a wonder,\n",
      "To respectise with me by their convention,\n",
      "And stir to do, and breathe his face:\n",
      "Yet you may feed.\n",
      "\n",
      "KING RICHARD III:\n",
      "The sister is the wise of duke\n",
      "==========\n",
      "\u001b[1m15,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m15,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ".\n",
      "\n",
      "ROMEO:\n",
      "Sir, looks, and to buy thee:\n",
      "I am a wanton told me, and I mean\n",
      "Will nothing please your gates, and soon as I know,\n",
      "For I had been else, and for\n",
      "==========\n",
      "\u001b[1m20,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m20,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ":\n",
      "O Warwick! times are not come.\n",
      "\n",
      "MONTAGUE:\n",
      "Good queen, God, I will not be beseech you:\n",
      "Thou hast no more, but he is a blows tog\n",
      "In a brawling wore\n",
      "==========\n",
      "\u001b[1m25,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m25,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ".\n",
      "\n",
      "DOREL:\n",
      "Behold with her, my lord?\n",
      "\n",
      "HORTENSIO:\n",
      "And then the surfeit of the body\n",
      "Of the charge.\n",
      "\n",
      "GRUMIO:\n",
      "Then, my good son.\n",
      "\n",
      "PETRUCHIO:\n",
      "==========\n",
      "\u001b[1m30,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m30,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "?\n",
      "\n",
      "\n",
      "DUKE OF YORK:\n",
      "Wife, I'll wring you, Duke of Warwick, where was Katharina?\n",
      "\n",
      "BUCKINGHAM:\n",
      "Take you your posts hence to him.\n",
      "\n",
      "MIRANDAMIL\n",
      "==========\n",
      "\u001b[1m35,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m35,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ",\n",
      "And, as I to God aught you:\n",
      "If your love, I'll be at your own:\n",
      "My mother, I come to this careless mistrust.\n",
      "\n",
      "SON:\n",
      "O, I have aged of acquainted fool\n",
      "==========\n",
      "\u001b[1m40,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m40,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ";\n",
      "Derves a piece awon smilling\n",
      "And cracking with the accountain of ere\n",
      "From what I charge himself: and yet I'll cry\n",
      "Your deices fortune, to sink and\n",
      "==========\n",
      "\u001b[1m45,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m45,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ",\n",
      "And fever thanks, came it to the tribunes\n",
      "And still the end over assist the north\n",
      "Which he would have said him. Therefore be covern'd:\n",
      "I cannot be to say, thou art an\n",
      "==========\n",
      "\u001b[1m50,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m50,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "s of the king!\n",
      "\n",
      "DUKE OF YORK:\n",
      "Stay, I will resolve you, and I pard thee.\n",
      "\n",
      "YORK:\n",
      "These words do choose in the busy's head of kings.\n",
      "\n",
      "DUKE OF YORK:\n",
      "\n",
      "==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model! It will save pytorch_model.bin periodically and after completion to the `trained_model` folder.\n",
    "# On a 2020 8-core iMac, this took ~25 minutes to run.\n",
    "ai.train(data, \n",
    "         batch_size=8, \n",
    "         num_steps=50000, \n",
    "         generate_every=5000, \n",
    "         save_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mROMEO:\u001b[0m\n",
      "Indew my mistress!\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "I puse thee, peace! the other souls that do chratch\n",
      "Ah, a treacherous buried soul! wa\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "Dear, my Lord, I baby, that's at,\n",
      "And for the little sweeter day to be fruited:\n",
      "For that I am buy of mine\n",
      "Supping, welcome to-temptinging the sun\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "Go on, then let us stand upon him.\n",
      "\n",
      "LADY Gentleman:\n",
      "Ah, power! I thank you, my lord.\n",
      "\n",
      "LADY ANNE:\n",
      "I know not: here we know, and am no remedy.\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "Romeo! my lord, I pity thee,\n",
      "To cut him to till the piteous charge\n",
      "To make thy minion with thy cle: my hand\n",
      "I ambush in another-born hateful peace,\n",
      "And\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "These too, sweet God! I will be direful.\n",
      "\n",
      "ROMEO:\n",
      "I will bend a signor Lucentio,\n",
      "And knew your streeting; that I\n",
      "Hath to a gave to sname!\n",
      "Lie\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "O, wretches, that thou art so wast a child.\n",
      "\n",
      "MIRANDA:\n",
      "Where is thy bawd?\n",
      "\n",
      "MIRANDA:\n",
      "What is the matter?\n",
      "\n",
      "FRIAR LAURENCE\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "Was ever drop, and awake, thou liest,\n",
      "Making me none, and learning it, when I do love,\n",
      "Where thou art thyself soft.\n",
      "\n",
      "MIRANDA:\n",
      "I think, my remed\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "Thou hast a stamp?\n",
      "\n",
      "JULIET:\n",
      "Pard, thou art a monst, and I may tell thee.\n",
      "\n",
      "ROMEO:\n",
      "I'll tell thee, and that thou mayst hear me kill.\n",
      "\n",
      "LADY CAPUL\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "Coldly, thou art a wid, thy son of heart,\n",
      "That still me traitors the wrest.\n",
      "\n",
      "BENVOLIO:\n",
      "You may be done, and make the duked soul,\n",
      "Where is King of Som\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "I see thee, believe them.\n",
      "\n",
      "BRUTUS:\n",
      "Romeo,\n",
      "Lieve you well, you free you,\n",
      "See him that the same, I have consent'd all;\n",
      "But to beat you on your mother,\n"
     ]
    }
   ],
   "source": [
    "# Generate text from it!\n",
    "ai.generate(10, prompt=\"ROMEO:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mROMEO:\u001b[0m\n",
      "The tongue of their lives and practise upon your death.\n",
      "\n",
      "JULIET:\n",
      "Are you not so; for I wish 'tis regraced\n",
      "As the sin and water for your highness\n",
      "To me without\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "I promise my soul's peril, my love's face is\n",
      "In my hand and my sinful broke:\n",
      "That I might die to keep my heart's glory,\n",
      "I feel my sorrow in my guest, and to\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "We were here a while: if you love him.\n",
      "\n",
      "PETRUCHIO:\n",
      "I'll tell you, sir, that I would sleep with words?\n",
      "\n",
      "HORTENSIO:\n",
      "Alas, you'll tell the brief of woe,\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "Tell me.\n",
      "\n",
      "LADY ANNE:\n",
      "I have made a bawd of day.\n",
      "\n",
      "LADY ANNE:\n",
      "I mean to sit down, as I have said,\n",
      "And I am in the fatal hold on\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "O, miserable brief! what's the news?\n",
      "\n",
      "JULIET:\n",
      "Peace, why have thy soul, thou art so lazed.\n",
      "Arise, as thou art as foolish to the field\n",
      "As\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "So is the trial of my brother wretches?\n",
      "\n",
      "ISABELLA:\n",
      "No best becomes a pitchcher of the event\n",
      "That ever she was paid to do thee good,\n",
      "Nor to be her son, and late\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "Not yet, I think it is, my lord,\n",
      "And prize allowing of mine own.\n",
      "\n",
      "JULIET:\n",
      "Alack, thou art a dear traitor;\n",
      "And let me be tall thy life to-night.\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "Are I to do with you? that's the house?\n",
      "\n",
      "MERCUTIO:\n",
      "Thou full of love: I will tell thee what thou art\n",
      "As fellow to be a pitcherous cheek of the guest.\n",
      "\n",
      "M\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "I do not go with thee, my lady, and you lie.\n",
      "\n",
      "DUKE OF YORK:\n",
      "I do ask my damny say.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "That's mine.\n",
      "\n",
      "KING RICHARD III:\n",
      "Well, I change\n",
      "==========\n",
      "\u001b[1mROMEO:\u001b[0m\n",
      "Faith, my name is a proud-face, a drunk.\n",
      "\n",
      "JULIET:\n",
      "Softly to God, the tempt of my silence\n",
      "To speak with thee.\n",
      "\n",
      "JULIET:\n",
      "Now, thou\n"
     ]
    }
   ],
   "source": [
    "# With your trained model, you can reload the model at any time by\n",
    "# providing the folder containing the pytorch_model.bin model weights + the config, and providing the tokenizer.\n",
    "ai2 = aitextgen(model_folder=\"trained_model\",\n",
    "                tokenizer_file=\"aitextgen.tokenizer.json\")\n",
    "\n",
    "ai2.generate(10, prompt=\"ROMEO:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
