{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting GPT-3\n",
    "\n",
    "GPT-3 (Generative Pre-trained Transformer 3) is a lanague model created by OpenAI. Including 175 billion parameters and 45TB of text data as training data. GPT-3 is not programmed to do any specific task, it can perform as chatbot, classifier, summarizer and other task.\n",
    "\n",
    "\n",
    "GPT-3 Playground</br>\n",
    "https://beta.openai.com/playground</br>\n",
    "https://beta.openai.com/codex-javascript-sandbox</br>\n",
    "https://gpttools.com/</br>\n",
    "\n",
    "All GPT-3 related company demos</br>\n",
    "https://gpt3demo.com/</br>\n",
    "\n",
    "some company example for gpt-3 usage</br>\n",
    "https://www.flowrite.com/</br>\n",
    "https://www.shortlyai.com/</br>\n",
    "https://www.othersideai.com/</br>\n",
    "https://www.copy.ai/</br>\n",
    "https://replika.com/</br>\n",
    "https://play.aidungeon.io/</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is prompting?\n",
    "Encouraging a pre-trained model to make particular predictions by providing a \"prompt\" specifying the task to be done. Predicting what is the next prediction or what is missing.\n",
    "\n",
    "\n",
    "a *prompt* is text we send to GPT-3 for prediction.\n",
    "\n",
    "(https://6b.eleuther.ai/ as example with TL;DR:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Engines in GPT-3 \n",
    "\n",
    "**text-davinci-002**\t\n",
    "Most capable GPT-3 model. \n",
    "Can do any task the other models can do, often with less context. In addition to responding to prompts, also supports inserting completions within text.\t\n",
    "`4,000 tokens`\t`Up to Jun 2021`\n",
    "\n",
    "\n",
    "**text-curie-001**\t\n",
    "Very capable, but faster and lower cost than Davinci.\t\n",
    "`2,048 tokens`\t`Up to Oct 2019`\n",
    "\n",
    "\n",
    "**text-babbage-001**\t\n",
    "Capable of straightforward tasks, very fast, and lower cost.\n",
    "\n",
    "`2,048 tokens`\t`Up to Oct 2019`\n",
    "\n",
    "\n",
    "**text-ada-001**\t\n",
    "Capable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost.\t\n",
    "`2,048 tokens`\n",
    "`Up to Oct 2019`\n",
    "\n",
    "### Parameters used in GPT-3\n",
    "\n",
    "* **Temperature**: entropy (proxy for creativity, lack of predictability). \n",
    "    * Low: Say the first thing that comes to mind. Good for classification - one specific answer\n",
    "    * High: Say anything that could possibly fit. Predict something creative.\n",
    "    \n",
    "* **Top-p**: distribution of probably of common tokens\n",
    "    * 1.0 - use all tokens in vocabulary\n",
    "    * 0.5 - use only 50% of the common tokens\n",
    "\n",
    "* **Stop sequence** - words to stop the generation.\n",
    "\n",
    "* **Frequency** - Repeating \n",
    "* **Presence** - Changing topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Tips for GPT-3 prompting\n",
    "\n",
    "Writing good prompts is understanding what GPT-3 knows about the world. **Wrong answer is sometime due to wrong question**. GPT-3 don't understands words, it turns words into token, which is understands as number.\n",
    "\n",
    "* Maximum token to prompt is 2048\n",
    "* use *stuffing* for repeating the same sets of questions\n",
    "* 1.2.3. numbers to generate list\n",
    "* : as instructions\n",
    "* using ### as end of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
